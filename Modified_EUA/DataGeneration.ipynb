{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataGeneration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxNvH4Aoye4N",
        "outputId": "7034ca6b-03f1-46f1-b0f1-f9e4aba69c71"
      },
      "source": [
        "!pip install pulp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pulp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/c4/0eec14a0123209c261de6ff154ef3be5cad3fd557c084f468356662e0585/PuLP-2.4-py3-none-any.whl (40.6MB)\n",
            "\u001b[K     |████████████████████████████████| 40.6MB 99kB/s \n",
            "\u001b[?25hCollecting amply>=0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/c5/dfa09dd2595a2ab2ab4e6fa7bebef9565812722e1980d04b0edce5032066/amply-0.1.4-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from amply>=0.1.2->pulp) (2.4.7)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from amply>=0.1.2->pulp) (0.17)\n",
            "Installing collected packages: amply, pulp\n",
            "Successfully installed amply-0.1.4 pulp-2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ5TxEeJ5Ll0"
      },
      "source": [
        "import pandas as pd\n",
        "import pulp as pl\n",
        "import numpy as np\n",
        "from functools import cmp_to_key"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s5zmFnlykiM"
      },
      "source": [
        "data_st = [\"{0}.csv\".format(i) for i in range(1 , 8)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXnEcRNLyoLs"
      },
      "source": [
        "fraction_of_data = 0.2  \n",
        "def solve_data_set(FILENAME , fraction_of_data , lp_mini = 0.1 , lp_time_limit = 300 , common_deadline=10,MEAN=2,STDDEV=1):\n",
        "  print (\"processing file :  \" + str(FILENAME) + \" fraction : \" + str(fraction_of_data))\n",
        "  experimental_results = pd.DataFrame()\n",
        "\n",
        "  ####################### READ DATA FROM THE FILES ################################\n",
        "  df = pd.read_csv(FILENAME).sample(frac=fraction_of_data, replace=False, random_state=1)\n",
        "\n",
        "  print(\"the number of rows in the data set is \" + str(df.shape[0]))\n",
        "\n",
        "  ## separating the users data frame and the server data frame into seperate data frames\n",
        "  ## storing the coverage information of the servers in dictionary\n",
        "  ## user data frame\n",
        "  userdf = df[['uId' , 'UCPU' , 'URAM' , 'UST' , 'UBAN']]\n",
        "  userdf = userdf.drop_duplicates(keep = 'first')\n",
        "\n",
        "  ## server data frame \n",
        "  serverdf = df[['siteId' , 'coverage' , 'SCPU' , 'SSTO' , 'SBAN' , 'SRAM']]\n",
        "  serverdf = serverdf.drop_duplicates(keep = 'first')\n",
        "\n",
        "  ## dictionary to store the coverage of the servers\n",
        "  coverage = {}\n",
        "  serversites = serverdf['siteId'].tolist()\n",
        "\n",
        "  for st in serversites:\n",
        "    new_df = df.loc[df['siteId'] == st]\n",
        "    ulist = new_df.uId.tolist()\n",
        "    coverage[st] = ulist\n",
        "\n",
        "  ## getting all the necessary values for the linear programming formulation\n",
        "  num_servers = serverdf.shape[0]\n",
        "  num_users = userdf.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  ## getting the list of all the server resources into np arrays \n",
        "  servercpu = np.array(serverdf['SCPU'].tolist())\n",
        "  serverstorage = np.array(serverdf['SSTO'].tolist())\n",
        "  serverram = np.array(serverdf['SRAM'].tolist())\n",
        "  serverbandwidth = np.array(serverdf['SBAN'].tolist())\n",
        "  serverid = np.array(serverdf['siteId'].tolist())\n",
        "\n",
        "\n",
        "  ## getting the list of all the user resources into np arrays \n",
        "  usercpu = np.array(userdf['UCPU'].tolist())\n",
        "  userstorage = np.array(userdf['UST'].tolist())\n",
        "  userram = np.array(userdf['URAM'].tolist())\n",
        "  userbandwidth = np.array(userdf['UBAN'].tolist())\n",
        "  userid = np.array(userdf['uId'].tolist())\n",
        "\n",
        "  ## randomly generating the execution time for the users \n",
        "  userexecutiontime = np.round(np.array(np.random.normal(MEAN , STDDEV , num_users)))\n",
        "  userexecutiontime = [max(i , 0) for i in userexecutiontime]\n",
        "\n",
        "  def is_in_coverage_of(j , i):\n",
        "    ## whether the jth user is in coverage of the ith server or not\n",
        "    site_id_of_server = serverid[i]\n",
        "    user_id_of_user = userid[j]\n",
        "    cover = coverage[site_id_of_server]\n",
        "    if user_id_of_user in cover:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "  \n",
        "\n",
        "\n",
        "  ####################### LINEAR PROGRAMMING SOLUTION ##################################\n",
        "  def linear_programming_solution(minimization_weight = 0.0):\n",
        "      server_user_time_vars = [[[\"x_{0}_{1}_{2}\".format(i , j , t) for t in range(common_deadline)] for j in range(num_users)] for i in range(num_servers)]\n",
        "      server_time_vars = [[\"y_{0}_{1}\".format(i , t) for t in range(common_deadline)] for i in range(num_servers)]\n",
        "\n",
        "      ## setting up the variables for the linear programming\n",
        "      ## X[i][j][t] is whether the jth user is allocated to the ith server at time t or not\n",
        "      ## Y[i][t] is whether the ith server is active at t\n",
        "\n",
        "      X = [[[pl.LpVariable(server_user_time_vars[i][j][t], 0, 1, cat='Integer') for t in range(common_deadline)] for j in range(num_users)] for i in range(num_servers)]\n",
        "      Y = [[pl.LpVariable(server_time_vars[i][t] , 0 , 1 , cat='Integer') for t in range(common_deadline)]for i in range(num_servers)]\n",
        "\n",
        "      ## create the optimization problem as the maximization problem\n",
        "      linearprogram = pl.LpProblem(\"euasolver\", pl.LpMaximize)\n",
        "\n",
        "      ## setting up the resource constraint equations \n",
        "      for t in range(common_deadline):\n",
        "        for i in range(num_servers):\n",
        "\n",
        "          ## cpu constraint at time t \n",
        "          constraintcpu = X[i][0][t] * usercpu[0]\n",
        "          for j in range(1 , num_users):\n",
        "            constraintcpu += X[i][j][t] * usercpu[j]\n",
        "          constraintcpu -= Y[i][t] * servercpu[i]\n",
        "\n",
        "          linearprogram += constraintcpu <= 0\n",
        "\n",
        "          ## storage constraint at time t\n",
        "          constraintstorage = X[i][0][t] * userstorage[0]\n",
        "          for j in range(1 , num_users):\n",
        "            constraintstorage += X[i][j][t] * userstorage[j]\n",
        "          constraintstorage -= Y[i][t] * serverstorage[i]\n",
        "\n",
        "          linearprogram += constraintstorage <= 0\n",
        "\n",
        "          ## ram constraints at time t\n",
        "          constraintram = X[i][0][t] * userram[0]\n",
        "          for j in range(1 , num_users):\n",
        "            constraintram += X[i][j][t] * userram[j]\n",
        "          constraintram -= Y[i][t] * serverram[i]\n",
        "\n",
        "          linearprogram += constraintram <= 0\n",
        "\n",
        "          ## bandwidth constraint at time t\n",
        "          constraintbandwidth = X[i][0][t] * userbandwidth[0]\n",
        "          for j in range(1 , num_users):\n",
        "            constraintbandwidth += X[i][j][t] * userbandwidth[j]\n",
        "          constraintbandwidth -= Y[i][t] * serverbandwidth[i]\n",
        "\n",
        "          linearprogram += constraintbandwidth <= 0\n",
        "\n",
        "\n",
        "      ## at any time t one user must go to one server only\n",
        "      for t in range(common_deadline):\n",
        "        for j in range(num_users):\n",
        "          serverconstraint = X[0][j][t]\n",
        "          for i in range(1 , num_servers):\n",
        "            serverconstraint += X[i][j][t];\n",
        "\n",
        "          linearprogram += serverconstraint <= 1\n",
        "\n",
        "      \n",
        "      ## proximity constraint at any time t\n",
        "      for i in range(num_servers):\n",
        "        for j in range(num_users):\n",
        "          ## find if the user is in coverage of the current server\n",
        "          is_user_in_server_coverage = df.loc[(df.siteId == serverid[i]) & (df.uId == userid[j])].shape[0]\n",
        "          \n",
        "          if is_user_in_server_coverage == 0:\n",
        "            ## if the user is not in the coverage of the server then for all the times the value of X[i][j][t] must be zero\n",
        "            for t in range(common_deadline):\n",
        "              user_out_of_coverage_constraint = X[i][j][t]\n",
        "              linearprogram += user_out_of_coverage_constraint <= 0 \n",
        "              linearprogram += user_out_of_coverage_constraint >= 0     \n",
        "\n",
        "\n",
        "      ## Making the system migration free\n",
        "      ## z_i_j = 1 if the jth user was allocated to the ith server\n",
        "      ## other wise 0\n",
        "\n",
        "      migration_control = [[\"z_{0}_{1}\".format(i , j) for j in range(num_users)] for i in range(num_servers)]\n",
        "\n",
        "      Z = [[pl.LpVariable(migration_control[i][j] , 0 , 1 , cat='Integer') for j in range(num_users)] for i in range(num_servers)]\n",
        "\n",
        "      ## for a particular user we must have only one server to which it belongs\n",
        "      for j in range(num_users):\n",
        "        migration_constraint = Z[0][j]\n",
        "        for i in range(1 , num_servers):\n",
        "          migration_constraint += Z[i][j]\n",
        "\n",
        "        linearprogram += migration_constraint <= 1\n",
        "\n",
        "\n",
        "      ## the user must be only allocated to one server for the total sum of its execution time only\n",
        "      for i in range(num_servers):\n",
        "        for j in range(num_users):\n",
        "          constraint_execution_time = X[i][j][0]\n",
        "          for t in range(1 , common_deadline):  \n",
        "            constraint_execution_time += X[i][j][t]\n",
        "          \n",
        "          linearprogram += constraint_execution_time <= Z[i][j] * userexecutiontime[j]\n",
        "          linearprogram += constraint_execution_time >= Z[i][j] * userexecutiontime[j]\n",
        "\n",
        "      obj = 0\n",
        "      maximization_weight = 1 - minimization_weight\n",
        "      for i in range(num_servers):\n",
        "        for t in range(common_deadline):\n",
        "          obj -= minimization_weight * Y[i][t]\n",
        "          for j in range(num_users):\n",
        "            obj += maximization_weight * X[i][j][t]\n",
        "\n",
        "      linearprogram += obj\n",
        "      # model.solve(pulp.PULP_CBC_CMD(maxSeconds=1000, msg=1, fracGap=0)) \n",
        "      status = linearprogram.solve(pl.PULP_CBC_CMD(timeLimit=lp_time_limit))\n",
        "\n",
        "      if status == pl.LpStatusOptimal:\n",
        "        num_users_allocated = 0\n",
        "        for i in range(num_servers):\n",
        "          for j in range(num_users):\n",
        "            for t in range(common_deadline):\n",
        "              num_users_allocated += pl.value(X[i][j][t])\n",
        "        \n",
        "        avg_users_allocated = (1.00 * num_users_allocated) / (common_deadline) \n",
        "        total_servers_used = 0\n",
        "        for i in range(num_servers):\n",
        "          for t in range(common_deadline):\n",
        "            total_servers_used += pl.value(Y[i][t])\n",
        "        \n",
        "        avg_servers_used = (1.00 * total_servers_used) / (common_deadline)\n",
        "        return (avg_users_allocated , avg_servers_used)\n",
        "      else:\n",
        "        print(\"unable to find the optimal solution\")\n",
        "        return (-1 , -1)\n",
        "\n",
        "  lpp_users_allocated = linear_programming_solution(minimization_weight=lp_mini)\n",
        "\n",
        "\n",
        "  ## performs the allocation of the users to the servers based on the comparators passed in\n",
        "  def perform_user_allocation(usr_key , server_key , verbose = False):\n",
        "      ## sorting the users and servers on the basis of the key\n",
        "      userslist = [i for i in range(num_users)]\n",
        "      serverlist = [i for i in range(num_servers)]\n",
        "      userslist.sort(key = usr_key)\n",
        "      serverlist.sort(key = server_key)\n",
        "\n",
        "      ## forming the allocation dictionary for the users \n",
        "      allocated = {}\n",
        "      ## maintaining the used servers\n",
        "      servers_used = {}\n",
        "      ## maintaining the execution time of the users\n",
        "      exectime = userexecutiontime.copy() \n",
        "      ## create the map of users to servers at time t\n",
        "      user_server_map = [[[0 for t in range(common_deadline)] for j in range(num_users)] for i in range(num_servers)]\n",
        "\n",
        "      for t in range(common_deadline):\n",
        "        ## for each time instant upto the common deadline do the following \n",
        "        \n",
        "        ## get the server resources\n",
        "        scpu = servercpu.copy()\n",
        "        sstorage = serverstorage.copy()\n",
        "        sram = serverram.copy()\n",
        "        sbandwidth = serverbandwidth.copy()\n",
        "        \n",
        "        ## utility function to perform the allocation of a user to the server\n",
        "        def allocate(j , i):\n",
        "          ## allocate the jth user to the ith server\n",
        "            scpu[i] = scpu[i] - usercpu[j] \n",
        "            sstorage[i] = sstorage[i] - userstorage[j] \n",
        "            sram[i] = sram[i] - userram[j] \n",
        "            sbandwidth[i] = sbandwidth[i] - userbandwidth[j]\n",
        "        \n",
        "        def canbeallocated(j , i):\n",
        "        # whether the jth user can be allocated to ith server or not\n",
        "            if is_in_coverage_of(j , i) == 0:\n",
        "              return 0\n",
        "            if usercpu[j] > scpu[i]:\n",
        "              return 0\n",
        "            if userstorage[j] > sstorage[i]:\n",
        "              return 0\n",
        "            if userram[j] > sram[i]:\n",
        "              return 0\n",
        "            if userbandwidth[j] > sbandwidth[i]:\n",
        "              return 0\n",
        "            remaining_time = common_deadline - t\n",
        "            if remaining_time < exectime[j] :\n",
        "              return 0\n",
        "            return 1\n",
        "\n",
        "\n",
        "        ### maintain edges first\n",
        "        for j in range(num_users):\n",
        "          usr = userslist[j]\n",
        "          \n",
        "          # if the users execution time is over then ignore and continue\n",
        "          if exectime[usr] <= 0:\n",
        "            continue\n",
        "\n",
        "          # if the user has already been allocated to a server then try allocate him to it again\n",
        "          if usr in allocated:\n",
        "            server_used = allocated[usr] ## get the server to which he was allocated\n",
        "            allocate(usr , server_used) ## allocate him to the same server\n",
        "            exectime[usr] -= 1 ## one unit of execution time is done \n",
        "            user_server_map[server_used][usr][t] = 1 ## usr has been allocated to the server so mark him in the map\n",
        "            servers_used[server_used] = 1 ## this server is marked as used\n",
        "          else:\n",
        "            continue\n",
        "          \n",
        "        ## look for new ones\n",
        "        for j in range(num_users):\n",
        "          usr = userslist[j]\n",
        "          \n",
        "          # if the users execution time is over then ignore and continue\n",
        "          if exectime[usr] <= 0:\n",
        "            continue\n",
        "\n",
        "          ## try to allocate the users that have not been allocated yet\n",
        "          if usr not in allocated:\n",
        "              ## try to allocate the user to the starting from left to right\n",
        "            for i in range(num_servers): \n",
        "              srvr = serverlist[i] ## this is the server that we are trying to allocate the user to\n",
        "              if canbeallocated(usr , srvr) == 1: ## we check if the user can be allocated to the server\n",
        "                allocate(usr , srvr) ## if yes, we do the allocation\n",
        "                allocated[usr] = srvr ## mark the user as allocated \n",
        "                exectime[usr] -= 1    ## reduce the execution time of the user\n",
        "                user_server_map[srvr][usr][t] = 1 ## store the mapping in the map\n",
        "                servers_used[srvr] = 1 ## mark the server as used\n",
        "                break\n",
        "\n",
        "      ## allocation is done \n",
        "      avgusers = 0 ## calculate the average number of users that have been allocated\n",
        "\n",
        "      ## simply take sum from the map\n",
        "      for i in range(num_servers):\n",
        "        for j in range(num_users):\n",
        "          for t in range(common_deadline):\n",
        "            avgusers += user_server_map[i][j][t]\n",
        "\n",
        "      avgusers = (1.00 * avgusers) / (common_deadline)\n",
        "\n",
        "      avgserversused = (1.00 * len(servers_used))\n",
        "      if verbose == True:\n",
        "        print (\"the average number of users allocated \" + str(avgusers))\n",
        "        print (\"the average number of servers used \" + str(avgserversused))\n",
        "      return (avgusers , avgserversused)\n",
        "  \n",
        "\n",
        "\n",
        "  ############################ RANDOM ALLOCATION ######################################\n",
        "  def random_allocation():\n",
        "      def userscompare(i , j):\n",
        "        if i < j:\n",
        "          return -1\n",
        "        elif i == j:\n",
        "          return 0\n",
        "        else:\n",
        "          return 1\n",
        "\n",
        "      def serverscompare(i , j):\n",
        "        if i < j:\n",
        "          return -1\n",
        "        elif i == j:\n",
        "          return 0\n",
        "        else:\n",
        "          return 1\n",
        "          \n",
        "      return perform_user_allocation(cmp_to_key(userscompare) , cmp_to_key(serverscompare))\n",
        "  random_user_allocated = random_allocation()\n",
        "\n",
        "\n",
        "\n",
        "  ############################ GREEDY ALLOCATION ##################################\n",
        "  def greedy_allocation():\n",
        "      def userscompare(i , j):\n",
        "        ei = userexecutiontime[i]\n",
        "        ej = userexecutiontime[j]\n",
        "        if ei < ej:\n",
        "          return -1\n",
        "        elif ei > ej:\n",
        "          return 1\n",
        "        else:    \n",
        "          return 0\n",
        "\n",
        "      def serverscompare(i , j):\n",
        "        if i < j:\n",
        "          return -1\n",
        "        elif i == j:\n",
        "          return 0\n",
        "        else:\n",
        "          return 1\n",
        "\n",
        "      return perform_user_allocation(cmp_to_key(userscompare) , cmp_to_key(serverscompare))\n",
        "    \n",
        "  greedy_user_allocated = greedy_allocation()\n",
        "\n",
        "\n",
        "\n",
        "  ############################ MCF ALLOCATION #########################\n",
        "  def most_capacity_first():\n",
        "    def userscompare(i , j):\n",
        "      ei = userexecutiontime[i]\n",
        "      ej = userexecutiontime[j]\n",
        "      if ei < ej:\n",
        "        return -1\n",
        "      elif ei > ej:\n",
        "        return 1\n",
        "      else:    \n",
        "        return 0\n",
        "\n",
        "    def serverscompare(i , j):\n",
        "      scapacityi = servercpu[i] + serverram[i] + serverbandwidth[i] + serverstorage[i]\n",
        "      scapacityj = servercpu[j] + serverram[j] + serverbandwidth[j] + serverstorage[j]\n",
        "\n",
        "      if scapacityi < scapacityj:\n",
        "        return -1\n",
        "      elif scapacityi > scapacityj:\n",
        "        return 1\n",
        "      else:    \n",
        "        return 0\n",
        "\n",
        "    return perform_user_allocation(cmp_to_key(userscompare) , cmp_to_key(serverscompare))\n",
        "  mcf_user_allocated = most_capacity_first()\n",
        "\n",
        "## for user we do a1 * resources + (1 - a1) * execution time = a1 * outgoing_edges + (1 - a1) * execution_time\n",
        "## for servers we do b1 * (weight_of_incoming edges) + (1 - b1) * resources available\n",
        "  results = pd.DataFrame()\n",
        "  A = []\n",
        "  B = []\n",
        "  C = []\n",
        "  def parameter_based_sorting():\n",
        "      hyperparameter_a = [0.1 , 0.3 , 0.5 , 0.7 , 0.9 , 1.00]\n",
        "      hyperparameter_b = [0.1 , 0.3 , 0.5 , 0.7 , 0.9 , 1.00]\n",
        "\n",
        "      ## computing the results in the results data frame\n",
        "      users_allocated = 0\n",
        "      used_servers = 0\n",
        "      a_optimal = 0\n",
        "      b_optimal = 0\n",
        "      for a1 in hyperparameter_a:\n",
        "        for b1 in hyperparameter_b:\n",
        "          def get_user_cost(j):\n",
        "            cost = (a1 / 4.00) * (usercpu[j] + userstorage[j] + userram[j] + userbandwidth[j]) + (1 - a1) * userexecutiontime[j]\n",
        "            return cost\n",
        "\n",
        "          def get_server_cost(i):\n",
        "            server_coverage = len(coverage[serverid[i]])\n",
        "            cost = (b1 / 4.00) * (servercpu[i] + serverstorage[i] + serverram[i] + serverbandwidth[i]) + (1 - b1) * server_coverage\n",
        "            return cost\n",
        "          def userscompare(i , j):\n",
        "            ## measure the cost of the ith user\n",
        "            ui = get_user_cost(i)\n",
        "            ## measure the cost of the jth user\n",
        "            uj = get_user_cost(j)\n",
        "            if ui < uj:\n",
        "              return -1\n",
        "            elif ui > uj:\n",
        "              return 1\n",
        "            else:    \n",
        "              return 0\n",
        "\n",
        "          def serverscompare(i , j):\n",
        "            ## measure the cost of the ith server\n",
        "            si = get_server_cost(i)\n",
        "            ## measure the cost of the jth server\n",
        "            sj = get_server_cost(j)\n",
        "\n",
        "            if si < sj:\n",
        "              return -1\n",
        "            elif si > sj:\n",
        "              return 1\n",
        "            else:\n",
        "              return 0\n",
        "          allocation = perform_user_allocation(cmp_to_key(userscompare) , cmp_to_key(serverscompare))\n",
        "          A.append(a1)\n",
        "          B.append(b1)\n",
        "          C.append(allocation[0])\n",
        "          if allocation[0] > users_allocated:\n",
        "            users_allocated = allocation[0]\n",
        "            used_servers = allocation[1]\n",
        "            a_optimal = a1\n",
        "            b_optimal = b1\n",
        "      results['A'] = A\n",
        "      results['B'] = B\n",
        "      results['U'] = C\n",
        "      return (users_allocated , used_servers , a_optimal , b_optimal)\n",
        "  mflow_user_allocated = parameter_based_sorting()\n",
        "\n",
        "\n",
        "  (lpp_user_ , lpp_server_) = lpp_users_allocated\n",
        "  (random_user_ , random_server_) = random_user_allocated\n",
        "  (greedy_user_ , greedy_server_) = greedy_user_allocated\n",
        "  (mcf_user_ , mcf_server_) = mcf_user_allocated\n",
        "  (mflow_user_ , mflow_server_, a_optimal_ , b_optimal_) = mflow_user_allocated\n",
        "  res = pd.DataFrame([[num_users , num_servers , common_deadline , MEAN , STDDEV,  lpp_user_, lpp_server_ , random_user_ , random_server_ , greedy_user_ , greedy_server_ , mcf_user_ , mcf_server_ , mflow_user_ , mflow_server_ , a_optimal_ , b_optimal_]], \\\n",
        "                     columns=['num_users' , 'num_servers' , 'common_deadline' , 'mean' , 'stddev' , 'lpp_user','lpp_server','random_user' , 'random_server' , 'greedy_user' , 'greedy_server' , 'mcf_user' , 'mcf_server' , 'mflow_user' , 'mflow_server' , 'a_optimal_' , 'b_optimal_'])\n",
        "\n",
        "  print(\"deadline \" + str(common_deadline) + \" , num-servers \" + str(num_servers) + \" num-users \" + str(num_users))\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrWXWhWEtchI"
      },
      "source": [
        "### Generating data from the same distribution(timelimit = TL for LPP SOLVER)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmzEC-Id3NPi",
        "outputId": "e5544098-f988-4ed5-a353-4c0059ff7fed"
      },
      "source": [
        "### data with deadline 10 and time limit 7 minutes\n",
        "TL = 400\n",
        "p = [0.05, 0.1 , 0.15 , 0.2 , 0.25 , 0.30, 0.35 , 0.40 , 0.45 , 0.50]\n",
        "for FILENAME in ['3.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "  for data_points in range(10):\n",
        "      print(\"sampling \" + str(p[data_points] * 100) + \" % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , p[data_points] , lp_mini=0.1 , lp_time_limit = TL, common_deadline=10)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'u_s_10_' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing file 3.csv\n",
            "sampling 5.0 % of the data\n",
            "preparing iteration 0\n",
            "processing file :  3.csv fraction : 0.05\n",
            "the number of rows in the data set is 258\n",
            "deadline 10 , num-servers 36 num-users 203\n",
            "sampling 10.0 % of the data\n",
            "preparing iteration 1\n",
            "processing file :  3.csv fraction : 0.1\n",
            "the number of rows in the data set is 516\n",
            "deadline 10 , num-servers 38 num-users 310\n",
            "sampling 15.0 % of the data\n",
            "preparing iteration 2\n",
            "processing file :  3.csv fraction : 0.15\n",
            "the number of rows in the data set is 773\n",
            "deadline 10 , num-servers 39 num-users 364\n",
            "sampling 20.0 % of the data\n",
            "preparing iteration 3\n",
            "processing file :  3.csv fraction : 0.2\n",
            "the number of rows in the data set is 1031\n",
            "deadline 10 , num-servers 42 num-users 407\n",
            "sampling 25.0 % of the data\n",
            "preparing iteration 4\n",
            "processing file :  3.csv fraction : 0.25\n",
            "the number of rows in the data set is 1289\n",
            "deadline 10 , num-servers 43 num-users 430\n",
            "sampling 30.0 % of the data\n",
            "preparing iteration 5\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "sampling 35.0 % of the data\n",
            "preparing iteration 6\n",
            "processing file :  3.csv fraction : 0.35\n",
            "the number of rows in the data set is 1804\n",
            "deadline 10 , num-servers 44 num-users 476\n",
            "sampling 40.0 % of the data\n",
            "preparing iteration 7\n",
            "processing file :  3.csv fraction : 0.4\n",
            "the number of rows in the data set is 2062\n",
            "deadline 10 , num-servers 45 num-users 490\n",
            "sampling 45.0 % of the data\n",
            "preparing iteration 8\n",
            "processing file :  3.csv fraction : 0.45\n",
            "the number of rows in the data set is 2320\n",
            "deadline 10 , num-servers 45 num-users 502\n",
            "sampling 50.0 % of the data\n",
            "preparing iteration 9\n",
            "processing file :  3.csv fraction : 0.5\n",
            "the number of rows in the data set is 2578\n",
            "deadline 10 , num-servers 47 num-users 518\n",
            "writing results to = u_s_10_3.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siMG1Tk2K7wI"
      },
      "source": [
        "\n",
        "common deadline = 10 and user maximization and server minimization for data set 3.csv and file output res_10_3.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jEZG-CbSdyP",
        "outputId": "86a862d5-0b02-46fe-d27e-972f4a4be9d6"
      },
      "source": [
        "### data with deadline 10 and time limit 7 minutes\n",
        "TL = 400\n",
        "for FILENAME in ['3.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "  for data_points in range(1 , 7):\n",
        "      print(\"sampling 30 % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , 0.3 , lp_mini=0.1 , lp_time_limit = TL, common_deadline=10)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'res_10_' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing file 3.csv\n",
            "sampling 30 % of the data\n",
            "preparing iteration 1\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "sampling 30 % of the data\n",
            "preparing iteration 2\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "sampling 30 % of the data\n",
            "preparing iteration 3\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "sampling 30 % of the data\n",
            "preparing iteration 4\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "sampling 30 % of the data\n",
            "preparing iteration 5\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "sampling 30 % of the data\n",
            "preparing iteration 6\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n",
            "deadline 10 , num-servers 43 num-users 453\n",
            "writing results to = res_10_3.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VMTPPmaLQmS"
      },
      "source": [
        "\n",
        "common deadline = 20 and user maximization and server minimization for data set 3.csv and file output res_20_3.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "e1wPVnTzVRsx",
        "outputId": "ea795161-81ec-4440-ea12-2646c5f4610a"
      },
      "source": [
        "TL = 400\n",
        "for FILENAME in ['3.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "  for data_points in range(1 , 7):\n",
        "      print(\"sampling 30 % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , 0.3 , lp_mini=0.1 , lp_time_limit = TL, common_deadline=20)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'res_20_' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing file 3.csv\n",
            "sampling 30 % of the data\n",
            "preparing iteration 1\n",
            "processing file :  3.csv fraction : 0.3\n",
            "the number of rows in the data set is 1546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c14f1e2c2e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sampling 30 % of the data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"preparing iteration \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolve_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILENAME\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlp_mini\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlp_time_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_deadline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mexperimental_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexperimental_results\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'res_20_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFILENAME\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-fff5dcb5c0b7>\u001b[0m in \u001b[0;36msolve_data_set\u001b[0;34m(FILENAME, fraction_of_data, lp_mini, lp_time_limit, common_deadline, MEAN, STDDEV)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m   \u001b[0mlpp_users_allocated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_programming_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminimization_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlp_mini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-fff5dcb5c0b7>\u001b[0m in \u001b[0;36mlinear_programming_solution\u001b[0;34m(minimization_weight)\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0;31m## ram constraints at time t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m           \u001b[0mconstraintram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muserram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mconstraintram\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muserram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m           \u001b[0mconstraintram\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mserverram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9ErfM6TLbJ-"
      },
      "source": [
        "\n",
        "common deadline = 15 and user maximization and server minimization for data set 4.csv and file output res_15_4.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdeqIMbWVZl0",
        "outputId": "b1d84a2b-a8c8-49ea-d7df-564d697b75b2"
      },
      "source": [
        "TL = 400\n",
        "for FILENAME in ['4.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "  for data_points in range(1 , 7):\n",
        "      print(\"sampling 30 % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , 0.3 , lp_mini=0.1 , lp_time_limit = TL, common_deadline=15)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'res_15_' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing file 4.csv\n",
            "sampling 30 % of the data\n",
            "preparing iteration 1\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 15 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 2\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 15 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 3\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 15 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 4\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 15 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 5\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "unable to find the optimal solution\n",
            "deadline 15 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 6\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 15 , num-servers 43 num-users 692\n",
            "writing results to = res_15_4.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93HVZgfgNvf-"
      },
      "source": [
        "### ONLY MAXIMIZING USERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emmCvo7GN02H",
        "outputId": "b62a484e-b6ba-4796-b700-edf7883d3f83"
      },
      "source": [
        "TL = 400\n",
        "for FILENAME in ['4.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "\n",
        "  for data_points in range(1 , 7):\n",
        "      print(\"sampling 30 % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , 0.3 , lp_mini=0.0 , lp_time_limit = TL)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'u_max_' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processing file 4.csv\n",
            "sampling 30 % of the data\n",
            "preparing iteration 1\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 10 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 2\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 10 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 3\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n",
            "deadline 10 , num-servers 43 num-users 692\n",
            "sampling 30 % of the data\n",
            "preparing iteration 4\n",
            "processing file :  4.csv fraction : 0.3\n",
            "the number of rows in the data set is 2629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uO40hURLtmE"
      },
      "source": [
        "## small data sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw2QL484C_R3"
      },
      "source": [
        "TL = 180\n",
        "for FILENAME in ['1.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "\n",
        "  for data_points in range(1 , 10):\n",
        "      print(\"sampling 30 % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , 0.3 , lp_mini=0.0 , lp_time_limit = TL)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'u_max_' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaEn0XheDEo6"
      },
      "source": [
        "TL = 180\n",
        "for FILENAME in ['1.csv']:\n",
        "  experimental_results = pd.DataFrame()\n",
        "  print (\"processing file \" + str(FILENAME))\n",
        "\n",
        "  for data_points in range(5):\n",
        "      print(\"sampling 30 % of the data\")\n",
        "      print (\"preparing iteration \" + str(data_points))\n",
        "      res = solve_data_set(FILENAME , 0.3 , lp_mini=0.1 , lp_time_limit = TL)\n",
        "      experimental_results = pd.concat([experimental_results , res])\n",
        "  fname = 'user_max_server_min_small' + FILENAME\n",
        "  print(\"writing results to = \" + str(fname))\n",
        "  experimental_results.to_csv(fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evurVQ4OE1Oy",
        "outputId": "b49d9dc0-3c61-4ea4-b53f-b1fe3b7bb657"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gru1Vugt3mJh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}